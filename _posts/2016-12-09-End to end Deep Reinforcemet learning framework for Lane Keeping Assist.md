---
layout:            post
title:             "End to end Deep Reinforcemet learning framework for Lane Keeping Assist"
menutitle:         "End to end Deep Reinforcemet learning framework for Lane Keeping Assist"
category:          Publications
author:            asallab
tags:              
---

[Ahmad A. Al Sallab, Mohammed Abdo, Senthil Yogamani, Etienne Perot. “End to end Deep Reinforcemet learning framework for Lane Keeping Assist”, The Thirtieth Annual Conference on Neural Information Processing Systems (NIPS), Machine Learning in Intelligent Transportation MLITS workshop, 05 Dec – 10 Dec, 2016, Barcelona Spain.](https://arxiv.org/abs/1612.04340)


Reinforcement learning is considered to be a strong AI paradigm which can be used to teach machines through interaction with the environment and learning from their mistakes, but it has not yet been successfully used for automotive applications. There has recently been a revival of interest in the topic, however, driven by the ability of deep learning algorithms to learn good representations of the environment. Motivated by Google DeepMind's successful demonstrations of learning for games from Breakout to Go, we will propose different methods for autonomous driving using deep reinforcement learning. This is of particular interest as it is difficult to pose autonomous driving as a supervised learning problem as it has a strong interaction with the environment including other vehicles, pedestrians and roadworks. As this is a relatively new area of research for autonomous driving, we will formulate two main categories of algorithms: 1) Discrete actions category, and 2) Continuous actions category. For the discrete actions category, we will deal with Deep Q-Network Algorithm (DQN) while for the continuous actions category, we will deal with Deep Deterministic Actor Critic Algorithm (DDAC). In addition to that, We will also discover the performance of these two categories on an open source car simulator for Racing called (TORCS) which stands for The Open Racing car Simulator. Our simulation results demonstrate learning of autonomous maneuvering in a scenario of complex road curvatures and simple interaction with other vehicles. Finally, we explain the effect of some restricted conditions, put on the car during the learning phase, on the convergence time for finishing its learning phase. 